{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bibliotecas\n",
    "import math, random\n",
    "import matplotlib\n",
    "import decimal\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0.5', '0.7'], ['1.0', '0.0']]\n"
     ]
    }
   ],
   "source": [
    "# lendo os arquivos de entrada\n",
    "initial_weights = open('initial_weights.txt','r+')\n",
    "\n",
    "def read_dataset(path_file):\n",
    "    '''função responsável em ler o arquivo de dataset'''\n",
    "    dataset = list()\n",
    "    file = open(path_file, 'r+')\n",
    "    for lines in file:\n",
    "        values_line = list()\n",
    "        \n",
    "        lines = lines.rstrip().split('; ')\n",
    "        for line in lines:\n",
    "            if ', ' in line:\n",
    "                dataset.append(line.rstrip().split(', '))\n",
    "            else:\n",
    "                dataset(line)\n",
    "    return dataset\n",
    "    \n",
    "dataset = read_dataset(\"dataset.txt\")\n",
    "print(dataset)\n",
    "    \n",
    "def read_def_network(path_file):\n",
    "    '''função responsável em ler o arquivo de definição da rede neural'''\n",
    "    file = open(path_file, \"r+\")\n",
    "    \n",
    "    network = list()\n",
    "    for line in file:\n",
    "        network.append(line.rstrip())\n",
    "    return network\n",
    "\n",
    "def_network = read_def_network('network.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rede neural composta por um número ajustável de neurônios e camadas e treinada via backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7794307159924072]\n"
     ]
    }
   ],
   "source": [
    "def create_network(initial_weights, n_hidden, n_output):\n",
    "    '''função responsável em criar a rede neural a partir do arquivo de definição'''\n",
    "    '''n_hidden pesos dos neurônios ocultos'''\n",
    "    '''n_output pesos dos neurônios de saída'''\n",
    "    i = 0\n",
    "    network = list()\n",
    "    lines = initial_weights.readlines()\n",
    "    while i < n_hidden:\n",
    "        layers = list()\n",
    "        for layer in [line.split(', ') for line in lines[i].rstrip().split('; ')]:\n",
    "            neurons = list()\n",
    "            for neuron in layer:\n",
    "                neurons.append(float(neuron))\n",
    "            layers.append(neurons)\n",
    "        network.append(layers)\n",
    "        i += 1\n",
    "    while i < n_hidden + n_output:\n",
    "        layers = list()\n",
    "        for layer in [line.split(', ') for line in lines[i].rstrip().split('; ')]:\n",
    "            neurons = list()\n",
    "            for neuron in layer:\n",
    "                neurons.append(float(neuron))\n",
    "            layers.append(neurons)\n",
    "        network.append(layers)\n",
    "        i += 1\n",
    "    return network\n",
    "\n",
    "def dot(v, w):\n",
    "    '''função responsável em realizar a soma pondera das entradas'''\n",
    "    return sum(v_i * w_i for v_i, w_i in zip(v, w))\n",
    "\n",
    "def sigmoid(t):\n",
    "    '''função responsável sobre a transferência do neurônio ativado'''\n",
    "    return 1 / (1 + math.exp(-t))\n",
    "\n",
    "def neuron_output(weights, inputs):\n",
    "    return sigmoid(dot(weights, inputs))\n",
    "\n",
    "def feed_forward(neural_network, input_vector):\n",
    "    \"\"\"takes in a neural network (represented as a list of lists of lists of weights)\n",
    "    and returns the output from forward-propagating the input\"\"\"\n",
    "    outputs = []\n",
    "\n",
    "    for layer in neural_network:\n",
    "        input_with_bias = input_vector + [1]             # add a bias input\n",
    "        output = [neuron_output(neuron, input_with_bias) # compute the output\n",
    "                  for neuron in layer]                   # for this layer\n",
    "        outputs.append(output)                           # and remember it\n",
    "\n",
    "        # the input to the next layer is the output of this one\n",
    "        input_vector = output\n",
    "    return outputs\n",
    "\n",
    "def backpropagate(network, input_vector, target):\n",
    "    hidden_outputs, outputs = feed_forward(network, input_vector) # TODO: deve ficar mais generico para n camadas\n",
    "    \n",
    "    # the output * (1 - output) is from the derivative of sigmoid\n",
    "    output_deltas = [output * (1 - output) * (output - target[i])\n",
    "                     for i, output in enumerate(outputs)]\n",
    "                     \n",
    "    # adjust weights for output layer (network[-1])\n",
    "    for i, output_neuron in enumerate(network[-1]):\n",
    "        for j, hidden_output in enumerate(hidden_outputs + [1]):\n",
    "            output_neuron[j] -= output_deltas[i] * hidden_output\n",
    "\n",
    "    # back-propagate errors to hidden layer\n",
    "    hidden_deltas = [hidden_output * (1 - hidden_output) * \n",
    "                      dot(output_deltas, [n[i] for n in network[-1]]) \n",
    "                     for i, hidden_output in enumerate(hidden_outputs)]\n",
    "\n",
    "    # adjust weights for hidden layer (network[0])\n",
    "    for i, hidden_neuron in enumerate(network[0]):\n",
    "        for j, input in enumerate(input_vector + [1]):\n",
    "            hidden_neuron[j] -= hidden_deltas[i] * input\n",
    "\n",
    "# construindo a rede neural\n",
    "network = create_network(initial_weights, 1, 1)  # TODO: mudar para o arquivo def a rede\n",
    "\n",
    "            \n",
    "# treinamento\n",
    "backpropagate(network, [float(dataset[0][0])], [float(dataset[0][1])]) # TODO: desenvolver para qualquer dataset\n",
    "\n",
    "\n",
    "def predict(input):\n",
    "    return feed_forward(network, input)[-1]\n",
    "\n",
    "print(predict([0.42000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funcionalidade que permita, via linha de comando, informar a sua implementação a estrutura de uma rede de teste (i.e., estrutura de camadas/neurônios, pesos iniciais, e fator de regularização), e um conjunto de treinamento, e que retorne o gradiente calculado para cada peso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funcionalidade que permita, via linha de comando, efetuar a verificação numérica do gradiente, a fim de checar a corretude da implementação de cada grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Um mecanismo para normalização das features/dados de treinamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mecanismo para uso de regularização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
