{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando bibliotecas auxiliares\n",
    "import math, random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32000\n",
      "0.75000\n",
      "0.68000\n",
      "0.98000\n",
      "0.83000\n",
      "0.75000\n",
      "0.02000\n",
      "0.28000\n"
     ]
    }
   ],
   "source": [
    "# lendo os arquivos de entrada\n",
    "def read_initial_weights(path_file):\n",
    "    '''função responsavel em ler o arquivo de pesos inicias'''\n",
    "    return open(path_file,'r+').readlines()\n",
    "\n",
    "def read_dataset(path_file):\n",
    "    '''função responsável em ler o arquivo de dataset'''\n",
    "    dataset = list()\n",
    "    file = open(path_file, 'r+')\n",
    "    for lines in file:\n",
    "        values_line = list()\n",
    "        dataset.append([lines.rstrip()])\n",
    "    return dataset\n",
    "    \n",
    "def read_def_network(path_file):\n",
    "    '''função responsável em ler o arquivo de definição da rede neural'''\n",
    "    file = open(path_file, \"r+\")\n",
    "    \n",
    "    network = list()\n",
    "    for line in file:\n",
    "        network.append(line.rstrip())\n",
    "    return network\n",
    "\n",
    "initial_weights = read_initial_weights('initial_weights.txt')\n",
    "#print('initial_weights:\\n', initial_weights)\n",
    "\n",
    "dataset = read_dataset(\"dataset.txt\")\n",
    "#print('dataset:\\n', dataset)\n",
    "\n",
    "def_network = read_def_network('network.txt')\n",
    "#print('def_network:\\n', def_network)\n",
    "\n",
    "for row in dataset:\n",
    "    result_split = row[0].rstrip().split('; ')\n",
    "    attributes = result_split[0].rstrip().split(', ')\n",
    "    expected_values = result_split[1].rstrip().split(', ')\n",
    "    \n",
    "    for index in range(len(attributes)):\n",
    "        print(attributes[index])\n",
    "        print(expected_values[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rede neural composta por um número ajustável de neurônios e camadas e treinada via backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Regulação:  0.250\n",
      "[INFO] Quantidade de entradas:  1\n",
      "[INFO] Quantidade de saídas:  1\n",
      "[INFO] Número de neurônios em cada camada oculta:  ['2'] \n",
      "\n",
      "0.40000, 0.10000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-471893917735>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;31m# construindo a rede neural\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdef_network\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_weights\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# TODO: mudar para o arquivo def a rede\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.00000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.13000\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# adicionando a entrada do vies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_propagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-471893917735>\u001b[0m in \u001b[0;36mcreate_network\u001b[0;34m(def_network, initial_weights)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneuron\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m', '\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneuron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0mnetwork_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'weights'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneuron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m', '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mnetwork_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneuron\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'list'"
     ]
    }
   ],
   "source": [
    "def create_network(def_network, initial_weights):\n",
    "    '''função responsável em criar a rede neural a partir dos arquivos de definição'''\n",
    "    '''def_network definição da estrutura da rede'''\n",
    "    '''initial_weights pesos inicias da rede'''\n",
    "    network = list()\n",
    "    \n",
    "    # trabalhando sobre o arquivo que define a rede\n",
    "    regulation = def_network[0]\n",
    "    def_network.pop(0) # remove a regulação já armazenada\n",
    "    \n",
    "    input_length = def_network[0]\n",
    "    def_network.pop(0)\n",
    "    \n",
    "    output_length = def_network[len(def_network)-1]\n",
    "    def_network.pop(len(def_network)-1)\n",
    "    \n",
    "    # imprimindo informações capturadas da definição da rede\n",
    "    print('[INFO] Regulação: ', regulation)\n",
    "    print('[INFO] Quantidade de entradas: ', input_length)\n",
    "    print('[INFO] Quantidade de saídas: ', output_length)\n",
    "    # imprimindo informações das camadas ocultas\n",
    "    print('[INFO] Número de neurônios em cada camada oculta: ', def_network, '\\n')\n",
    "    \n",
    "    # trabalhando sobre o arquivo de quefine os pesos\n",
    "    for weights in initial_weights:\n",
    "        layers = weights.rstrip().split('; ')\n",
    "        network_layer = list()\n",
    "        for neuron in layers:\n",
    "            print(neuron)\n",
    "            if ', ' in neuron:\n",
    "                network_layer.append({'weights': neuron.rstrip().split(', ')})\n",
    "            else:\n",
    "                network_layer.append(neuron)\n",
    "        network.append(network_layer)\n",
    "    print('[INFO] Rede neural criada: ', network, '\\n')\n",
    "    return network\n",
    "\n",
    "def dot(weights, inputs):\n",
    "    print('weights: ', weights)\n",
    "    print('inputs: ', inputs)\n",
    "    return sum(float(weight_i) * float(input_i) for weight_i, input_i in zip(weights, inputs))\n",
    "\n",
    "def sigmoid(activation):\n",
    "    '''função responsável por calcular a aproximação da função'''\n",
    "    return 1 / (1 + math.exp(-activation))\n",
    "\n",
    "def forward_propagate(network, row):\n",
    "    ''''''\n",
    "    inputs = row\n",
    "    \n",
    "    index = 0\n",
    "    for layer in network:\n",
    "        new_inputs = list()\n",
    "        if index != len(network)-1:\n",
    "            new_inputs.append(1.00000) # adicionando a entrada do vies\n",
    "        for neuron in layer:\n",
    "            activation = dot(neuron['weights'], inputs)\n",
    "            neuron['output'] = sigmoid(activation)\n",
    "            new_inputs.append(neuron['output'])\n",
    "        inputs = new_inputs\n",
    "        index = index + 1\n",
    "    return inputs\n",
    "\n",
    "\n",
    "# Calculate the derivative of an neuron output\n",
    "def transfer_derivative(output):\n",
    "    return output * (1.0 - output)\n",
    "\n",
    "# Backpropagate error and store in neurons\n",
    "def backward_propagate_error(network, expected):\n",
    "    for i in reversed(range(len(network))):\n",
    "        layer = network[i]\n",
    "        errors = list()\n",
    "        if i != len(network)-1:\n",
    "            for j in range(len(layer)):\n",
    "                error = 0.0\n",
    "                for neuron in network[i + 1]:\n",
    "                    error += (float(neuron['weights'][j]) * neuron['delta'])\n",
    "                    errors.append(error)\n",
    "        else:\n",
    "            for j in range(len(layer)):\n",
    "                neuron = layer[j]\n",
    "                errors.append(expected[j] - neuron['output'])\n",
    "            print('errors', errors)\n",
    "        for j in range(len(layer)):\n",
    "            neuron = layer[j]\n",
    "            neuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n",
    "\n",
    "def update_weights(network, row, l_rate):\n",
    "    for i in range(len(network)):\n",
    "        inputs = row[:-1]\n",
    "        if i != 0:\n",
    "            inputs = [neuron['output'] for neuron in network[i - 1]]\n",
    "        for neuron in network[i]:\n",
    "            for j in range(len(inputs)):\n",
    "                neuron['weights'][j] += l_rate * neuron['delta'] * inputs[j]\n",
    "            neuron['weights'][-1] += l_rate * neuron['delta']\n",
    "\n",
    "def train_network(network, dataset, l_rate, n_epoch, n_outputs):\n",
    "    for epoch in range(n_epoch):\n",
    "        sum_error = 0\n",
    "        for row in dataset:\n",
    "            outputs = forward_propagate(network, row)\n",
    "            expected = [0 for i in range(n_outputs)]\n",
    "            \n",
    "            print('expected: ', expected[row[-1]])\n",
    "            \n",
    "            expected[row[-1]] = 1\n",
    "            sum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n",
    "            backward_propagate_error(network, expected)\n",
    "            update_weights(network, row, l_rate)\n",
    "        print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n",
    "\n",
    "\n",
    "# construindo a rede neural\n",
    "network = create_network(def_network, initial_weights)  # TODO: mudar para o arquivo def a rede\n",
    "row = [1.00000, 0.13000] # adicionando a entrada do vies\n",
    "output = forward_propagate(network, row)\n",
    "print('[INFO] valor de saída (fx): ', output, '\\n')\n",
    "\n",
    "backward_propagate_error(network, [0.90000])\n",
    "\n",
    "# visualizando a rede com os pesos calculados\n",
    "for layer in network:\n",
    "    for neuron in layer:\n",
    "        print(neuron)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funcionalidade que permita, via linha de comando, informar a sua implementação a estrutura de uma rede de teste (i.e., estrutura de camadas/neurônios, pesos iniciais, e fator de regularização), e um conjunto de treinamento, e que retorne o gradiente calculado para cada peso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.60874   0.59484\n",
    "0.79597"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funcionalidade que permita, via linha de comando, efetuar a verificação numérica do gradiente, a fim de checar a corretude da implementação de cada grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range([1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Um mecanismo para normalização das features/dados de treinamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mecanismo para uso de regularização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
